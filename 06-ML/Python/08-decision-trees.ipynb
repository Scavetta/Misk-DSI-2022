{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eebb887-433a-4bbd-bf26-2fcd6fd5c7c0",
   "metadata": {},
   "source": [
    "# Module 08: Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86856b65-5400-439b-a96f-b6f67b688f54",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed6e067-5e5b-4cc5-8da4-d64fffc5fe62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotnine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6d696c6f752f446f63756d656e74732f6d69736b2d4453492f4d69736b2d4453492d32303232/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6d696c6f752f446f63756d656e74732f6d69736b2d4453492f4d69736b2d4453492d32303232/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb#ch0000002vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6d696c6f752f446f63756d656e74732f6d69736b2d4453492f4d69736b2d4453492d32303232/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb#ch0000002vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mplotnine\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6d696c6f752f446f63756d656e74732f6d69736b2d4453492f4d69736b2d4453492d32303232/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6d696c6f752f446f63756d656e74732f6d69736b2d4453492f4d69736b2d4453492d32303232/workspaces/Misk-DSI-2022/06-ML/Python/08-decision-trees.ipynb#ch0000002vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# Modeling packages\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotnine'"
     ]
    }
   ],
   "source": [
    "# Helper packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import partial_dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfaa521-9450-49a5-9f46-f90039698754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ames housing data\n",
    "ames = pd.read_csv(\"../../00-data/ML/ames.csv\")\n",
    "\n",
    "# create train/test split\n",
    "train, test = train_test_split(ames, train_size=0.7, random_state=123)\n",
    "\n",
    "# separate features from labels and only use numeric features\n",
    "X_train = train.drop(\"Sale_Price\", axis=1)\n",
    "y_train = train[[\"Sale_Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de2bda-f40d-4ce4-9939-d7616fb95c4d",
   "metadata": {},
   "source": [
    "## Basic implementation\n",
    "\n",
    "### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c344e316-7121-43e5-a1e2-ebec40524607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: create model object\n",
    "dt_mod = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "# Step 2: fit/train model\n",
    "dt_fit = dt_mod.fit(X_train[[\"Gr_Liv_Area\", \"Year_Built\"]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80b0c0-22ad-4d02-967a-feacdb7a6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_fit.get_n_leaves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b4726a-e43e-4acf-b1c4-786a64cac28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(dt_fit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65822349-8890-4207-8d77-0ebfff1613c6",
   "metadata": {},
   "source": [
    "### Cross-validated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa1ed2-c166-4dc3-bab7-79b320d7d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DT model object\n",
    "dt_mod = DecisionTreeRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 5 fold CV object\n",
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# fit model with 5-fold CV\n",
    "results = cross_val_score(dt_mod, X_train[[\"Gr_Liv_Area\", \"Year_Built\"]], \n",
    "                          y_train, cv=kfold, scoring=loss)\n",
    "\n",
    "\n",
    "np.round(np.abs(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb58f4-72c4-415e-9179-4d9618132390",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b0705-de43-4727-b2d4-6f15386c3c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new feature set with encoded features\n",
    "X_train_encoded = pd.get_dummies(X_train)\n",
    "\n",
    "# fit model with 5-fold CV\n",
    "results = cross_val_score(dt_mod, X_train_encoded, y_train, cv=kfold, scoring=loss)\n",
    "\n",
    "np.abs(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6aaea8-03de-472d-bb44-3cb3bc8212bb",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bfe7f-fa0b-4f7a-8c30-ff0d5ac97fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model object\n",
    "dt_mod = DecisionTreeRegressor()\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 5 fold CV object\n",
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {\n",
    "  'ccp_alpha': [1e-1, 1e-5, 1e-10],\n",
    "  'max_depth': [1, 8, 15],\n",
    "  'min_samples_split': [2, 21, 40]\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f373b2c-2af1-4043-9d9c-11c2af1c7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(dt_mod, hyper_grid, cv=kfold, scoring=loss)\n",
    "results = grid_search.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Optimal penalty parameter in grid search\n",
    "results.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9c950-c187-4662-90f1-434f470412ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model's cross validated RMSE\n",
    "round(abs(results.best_score_), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c626e9-38e6-4981-973a-b184be0c9707",
   "metadata": {},
   "source": [
    "## Feature interpretation\n",
    "\n",
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fec803-ae88-4a85-979a-3ee4cb49e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final model object\n",
    "best_mod = results.best_estimator_\n",
    "best_mod_fit = best_mod.fit(X_train_encoded, y_train)\n",
    "\n",
    "# extract feature importances\n",
    "vi = pd.DataFrame({'feature': X_train_encoded.columns,\n",
    "                   'importance': best_mod_fit.feature_importances_})\n",
    "\n",
    "# get top 20 influential features\n",
    "top_20_features = vi.nlargest(20, 'importance')\n",
    "\n",
    "# plot feature importance\n",
    "(ggplot(top_20_features, aes(x='importance', y='reorder(feature, importance)'))\n",
    " + geom_point()\n",
    " + labs(y=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5994693-cac2-4ece-ad9e-68524dd6bbf3",
   "metadata": {},
   "source": [
    "### Feature relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b833c12-3832-42d9-bc5e-52ac69d67679",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results = partial_dependence(\n",
    "  best_mod_fit, X_train_encoded, \"Garage_Cars\", kind='average',\n",
    "  percentiles=(0, 1)) \n",
    "  \n",
    "pd_output = pd.DataFrame({'Garage_Cars': pd_results['values'][0],\n",
    "                          'yhat': pd_results['average'][0]})\n",
    "                          \n",
    "(ggplot(pd_output, aes('Garage_Cars', 'yhat'))\n",
    "  + geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18f75a-86dd-4cd1-860d-db7a57c63e43",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Using the Boston housing data set, where the response feature is the median value of homes within a census tract (`cmedv`):\n",
    "\n",
    "1. Apply a decision tree model with all features.\n",
    "2. How many internal splitting nodes optimize model performance?\n",
    "3. Can you identify the predicted values and SEE in the terminal nodes?\n",
    "4. Identify the first feature split node and explain how it is splitting this feature.\n",
    "5. Which 10 features are considered most influential? Are these the same features that have been influential in previous models?\n",
    "6. Now perform 1-5 to the Attrition dataset, which is classification model rather than a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d9b4ae-28de-4280-b8cc-aa2a52b429fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ed549bf1dfff0c9e2fa63787d3c672338cbace345788ee41613d78c6db524064"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
