{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad31b841-575d-4498-b0f1-81fec51e1a43",
   "metadata": {},
   "source": [
    "# Module 10: Random Forests\n",
    "\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4512fa15-e790-4e64-9ea6-3ff401c4159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e20556e-e25b-4cea-82cb-50a33fb3785b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ames housing data\n",
    "ames = pd.read_csv(\"../../00-data/ML/ames.csv\")\n",
    "\n",
    "# create train/test split\n",
    "train, test = train_test_split(ames, train_size=0.7, random_state=123)\n",
    "\n",
    "# separate features from labels and only use numeric features\n",
    "X_train = train.drop(\"Sale_Price\", axis=1)\n",
    "y_train = train[[\"Sale_Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885fe1d-63b5-43a9-a70c-3cd9ec541705",
   "metadata": {},
   "source": [
    "## Out-of-the-box performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e1fc21-806b-4312-adda-4be7db8daca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode our quality-based features \n",
    "ord_cols = list(X_train.filter(regex=(\"Qual$|QC$|Cond$\")).columns)\n",
    "lvs = [\"Very_Poor\", \"Poor\", \"Fair\", \"Below_Average\", \"Average\", \"Typical\", \n",
    "       \"Above_Average\", \"Good\", \"Very_Good\", \"Excellent\", \"Very_Excellent\"]\n",
    "val = range(0, len(lvs))\n",
    "lvl_map = dict(zip(lvs, val))\n",
    "category_mapping = [{'col': col, 'mapping': lvl_map} for col in ord_cols]\n",
    "ord_encoder = OrdinalEncoder(cols=ord_cols, mapping=category_mapping)\n",
    "\n",
    "# one hot encode remaining nominal features\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# combine into a pre-processing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "  remainder=\"passthrough\",\n",
    "  transformers=[\n",
    "   (\"ord_encode\", ord_encoder, ord_cols),\n",
    "   (\"one-hot\", encoder, selector(dtype_include=\"object\")),\n",
    "   ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6369452c-b696-42cb-b506-9fcf9b27bade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/sklearn/pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/sklearn/pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/sklearn/pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/sklearn/pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "/Users/b294776/Desktop/Workspace/Projects/misk/misk-homl/venv/lib/python3.8/site-packages/sklearn/pipeline.py:346: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28062.467835371743"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random forest estimator\n",
    "rf_mod = RandomForestRegressor()\n",
    "\n",
    "# create modeling pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"rf_mod\", rf_mod),\n",
    "])\n",
    "\n",
    "# define loss function\n",
    "loss = 'neg_root_mean_squared_error'\n",
    "\n",
    "# create 5 fold CV object\n",
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# fit model with 5-fold CV\n",
    "results = cross_val_score(model_pipeline, X_train, y_train, cv=kfold, scoring=loss)\n",
    "\n",
    "np.abs(np.mean(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47659d6-7cb5-432b-9e9b-0008c5ba7c95",
   "metadata": {},
   "source": [
    "## Tuning strategies\n",
    "\n",
    "### Cartesian grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba1bd37-3677-4ad2-b68f-2a1e35080481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest estimator with 1,000 trees\n",
    "rf_mod = RandomForestRegressor(n_estimators=1000)\n",
    "\n",
    "# create modeling pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"rf_mod\", rf_mod),\n",
    "])\n",
    "\n",
    "# Create grid of hyperparameter values\n",
    "hyper_grid = {\n",
    "  'rf_mod__max_features': [.05, .15, .25, .333, .4],\n",
    "  'rf_mod__min_samples_leaf': [1, 3, 5, 10],\n",
    "  'rf_mod__bootstrap': [True, False],\n",
    "  'rf_mod__max_samples': [.5, .63, .8]\n",
    "  }\n",
    "  \n",
    "# Tune a knn model using grid search\n",
    "grid_search = GridSearchCV(model_pipeline, hyper_grid, cv=kfold, scoring=loss, n_jobs=-1)\n",
    "results = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best model score\n",
    "np.abs(results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7359d-89ad-4a34-9f76-6b2d77420389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameter values\n",
    "results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca8cd4-3a96-4257-8fdb-cac51722bf54",
   "metadata": {},
   "source": [
    "### Random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcf564-2ad9-4b17-a3ea-9a4b2c8e5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid of hyperparameter values\n",
    "hyper_distributions = {\n",
    "  'rf_mod__max_features': uniform(.05, .35),\n",
    "  'rf_mod__min_samples_leaf': randint(1, 9),\n",
    "  'rf_mod__bootstrap': [True, False],\n",
    "  'rf_mod__max_samples': uniform(.5, .3)\n",
    "  }\n",
    "  \n",
    "# Tune a knn model using grid search\n",
    "random_search = RandomizedSearchCV(\n",
    "  model_pipeline, \n",
    "  param_distributions=hyper_distributions, \n",
    "  n_iter=20,\n",
    "  cv=kfold, \n",
    "  scoring=loss, \n",
    "  n_jobs=-1, \n",
    "  random_state=13\n",
    "  )\n",
    "random_search_results = random_search.fit(X_train, y_train)\n",
    "\n",
    "# best model score\n",
    "np.abs(random_search_results.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6c1fa-e18c-472e-a8d5-e314ccf1a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best hyperparameter values\n",
    "random_search_results.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d719ba-60e1-4c0c-af8b-6fefceebf487",
   "metadata": {},
   "source": [
    "## Feature interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84695d6-81d7-4325-988f-e52492d51b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final model object\n",
    "X_encoded = preprocessor.fit_transform(X_train)\n",
    "final_model = RandomForestRegressor(\n",
    "  n_estimators=1000,\n",
    "  max_features=0.21,\n",
    "  max_samples=0.65,\n",
    "  min_samples_leaf=1,\n",
    "  bootstrap=False\n",
    ")\n",
    "final_model_fit = final_model.fit(X_encoded, y_train)\n",
    "\n",
    "# extract feature importances\n",
    "vi = pd.DataFrame({'feature': preprocessor.get_feature_names(),\n",
    "                   'importance': final_model_fit.feature_importances_})\n",
    "\n",
    "# get top 20 influential features\n",
    "top_20_features = vi.nlargest(20, 'importance')\n",
    "\n",
    "# plot feature importance\n",
    "(ggplot(top_20_features, aes(x='importance', y='reorder(feature, importance)'))\n",
    " + geom_point()\n",
    " + labs(y=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1a0ec-2f02-4b61-b0d2-5c5bbbfe291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.DataFrame(X_encoded, columns=preprocessor.get_feature_names())\n",
    "pd_results = partial_dependence(\n",
    "  final_model_fit, X_encoded, \"Gr_Liv_Area\", kind='average',\n",
    "  percentiles=(0, 1)) \n",
    "  \n",
    "pd_output = pd.DataFrame({'Gr_Liv_Area': pd_results['values'][0],\n",
    "                          'yhat': pd_results['average'][0]})\n",
    "                          \n",
    "(ggplot(pd_output, aes('Gr_Liv_Area', 'yhat'))\n",
    "  + geom_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da544e0c-5317-4130-88da-b1057874e8ce",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Using the Boston housing data set, where the response feature is the median value of homes within a census tract (`cmedv`):\n",
    "\n",
    "1. Apply a default random forest model with the same features you used in the bagging module. How does the out-of-the-box random forest model perform compared to the bagging module?\n",
    "2. Assess the number of trees in your random forest model.\n",
    "   - How many trees are applied?\n",
    "   - Was it enough to stabilize the loss function or do you need to add more?\n",
    "3. Perform a full cartesian grid search across various values of:\n",
    "   - $m_{try}$\n",
    "   - tree complexity (i.e. max depth, node size)\n",
    "   - sampling scheme\n",
    "4. How long did the above grid search take? Which model gave the best performance?\n",
    "5. Now run a random grid search across the same hyperparameter grid but restrict the time or number of models to run to 50% of the models ran in the full cartesian. How does the random grid search results compare?\n",
    "6. Pick your best random forest model. Which 10 features are considered most influential? Are these the same features that have been influential in previous models?\n",
    "7. Create partial dependence plots for the top two most influential features. Explain the relationship between the feature and the predicted values.\n",
    "8. Now perform 1-7 to the Attrition dataset, which is classification model rather than a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5643da-cbdc-4e78-bb9d-1ae3b1881cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
