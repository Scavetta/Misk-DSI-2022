{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64a4b781-83c0-47ba-9b3e-70634638605a",
   "metadata": {},
   "source": [
    "# Stacked Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f13ef-4ece-42f1-9ed3-5acb1d750731",
   "metadata": {},
   "source": [
    "## Prerequisites "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48c4503-d8a3-4990-8b1f-b898965f1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper packages\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Modeling packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bba15d-a772-4280-b50f-551c68ddd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ames housing data\n",
    "ames = pd.read_csv(\"../data/ames.csv\")\n",
    "\n",
    "# create train/test split\n",
    "train, test = train_test_split(ames, train_size=0.7, random_state=123)\n",
    "\n",
    "# separate features from labels and only use numeric features\n",
    "X_train = train.drop(\"Sale_Price\", axis=1)\n",
    "y_train = train[[\"Sale_Price\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cc7bf8-f55f-4b10-892c-f1a2d61ded9e",
   "metadata": {},
   "source": [
    "## Implementing stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395eadc-a286-4bb4-801a-fddc80ce854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode our quality-based features \n",
    "ord_cols = list(X_train.filter(regex=(\"Qual$|QC$|Cond$\")).columns)\n",
    "lvs = [\"Very_Poor\", \"Poor\", \"Fair\", \"Below_Average\", \"Average\", \"Typical\", \n",
    "       \"Above_Average\", \"Good\", \"Very_Good\", \"Excellent\", \"Very_Excellent\"]\n",
    "val = range(0, len(lvs))\n",
    "lvl_map = dict(zip(lvs, val))\n",
    "category_mapping = [{'col': col, 'mapping': lvl_map} for col in ord_cols]\n",
    "ord_encoder = OrdinalEncoder(cols=ord_cols, mapping=category_mapping)\n",
    "\n",
    "# one hot encode remaining nominal features\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# combine into a pre-processing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "  remainder=\"passthrough\",\n",
    "  transformers=[\n",
    "   (\"ord_encode\", ord_encoder, ord_cols),\n",
    "   (\"one-hot\", encoder, selector(dtype_include=\"object\")),\n",
    "   ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74521044-651a-4f71-a6ed-4e5ae56bcaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model\n",
    "lm_mod = linear_model.LinearRegression()\n",
    "\n",
    "# decision tree model\n",
    "dt_mod = DecisionTreeRegressor(\n",
    "  ccp_alpha=0.1, \n",
    "  max_depth=15, \n",
    "  min_samples_split=40\n",
    ")\n",
    "\n",
    "# random forest model\n",
    "rf_mod = RandomForestRegressor(\n",
    "  n_estimators=1000,\n",
    "  max_features=0.21,\n",
    "  max_samples=0.65,\n",
    "  min_samples_leaf=1,\n",
    "  bootstrap=False\n",
    ")\n",
    "\n",
    "# XGBoost GBM model\n",
    "xgb_mod = xgb.XGBRegressor(\n",
    "  n_estimators=5000,\n",
    "  learning_rate=0.1,\n",
    "  max_depth=3,\n",
    "  min_child_weight=1,\n",
    "  subsample=1,\n",
    "  colsample_bytree=0.75,\n",
    "  colsample_bylevel=0.75,\n",
    "  colsample_bynode=0.75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf817a-207d-4e64-b200-85276a6a0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model pipeline\n",
    "lm_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"lm_mod\", lm_mod),\n",
    "])\n",
    "\n",
    "# decision tree pipeline\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"dt_mod\", dt_mod),\n",
    "])\n",
    "\n",
    "# random forest pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"rf_mod\", rf_mod),\n",
    "])\n",
    "\n",
    "# XGBoost pipeline\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "  (\"preprocessor\", preprocessor),\n",
    "  (\"xgb_mod\", xgb_mod),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6013bf1-3a90-4fb1-9d86-509173cdff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "  ('Linear regression', lm_pipeline),\n",
    "  ('Decision tree', dt_pipeline),\n",
    "  ('Random forest', rf_pipeline),\n",
    "  ('XGBoost', xgb_pipeline)\n",
    "  ]\n",
    "              \n",
    "stacking_regressor = StackingRegressor(\n",
    "  estimators=estimators, \n",
    "  final_estimator=RidgeCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0bad41-e64b-43fa-9de6-7bc59ada7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 fold CV object\n",
    "kfold = KFold(n_splits=5, random_state=123, shuffle=True)\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "results = cross_val_score(\n",
    "  stacking_regressor, \n",
    "  X_train, \n",
    "  y_train, \n",
    "  cv=kfold, \n",
    "  scoring='neg_root_mean_squared_error'\n",
    ")\n",
    "\n",
    "# get average CV RMSE\n",
    "abs(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84dd388-9df7-4c31-894d-40302c1cd3ed",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Using the Boston housing data set, where the response feature is the median value of homes within a census tract (`cmedv`):\n",
    "\n",
    "1. Recreate the optimal models identified from the exercises in the [linear regression](https://misk-data-science.github.io/misk-homl/docs/notebooks/04-linear-regression.html#Exercises),  [decision tree](https://misk-data-science.github.io/misk-homl/docs/notebooks/09-decision-trees.html#Exercises), [random forest](https://misk-data-science.github.io/misk-homl/docs/notebooks/11-random-forests.html#Exercises), and [gradient boosting](https://misk-data-science.github.io/misk-homl/docs/notebooks/12-gbm.html#Exercises) modules.\n",
    "2. Apply a stacked model and compare the model performance to the individual models.\n",
    "3. Now repeat 1 & 2 for the Attrition dataset, which is classification model rather than a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453cbd3-753f-4250-9cb6-14560c7b8938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
